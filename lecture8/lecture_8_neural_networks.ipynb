{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we'll be looking at various kinds of neural networks.  Neural networks in python are a very quickly evolving area, and there are many different competing packages for working with them.  Unfortunately, there's not yet a standard set of packages in scikit-learn like we've seen for many other machine learning methods.  \n",
    "\n",
    "Most of the packages are high level wrappers around [Theano](http://deeplearning.net/software/theano/), which is a mathematical package for easily working with numerical expressions of arrays and matrices and their gradients.  Additionally, Theano code will also run seamlessly on a GPU if one is available.  This makes training much, much faster.  Here's an [ipython notebook](http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb) on Theano if you're interested. \n",
    "\n",
    "[Keras](https://github.com/fchollet/keras/) is a relatively new package.  It looks to be a good balance between sophistication and simplicity.  Installation instructions are at that link.\n",
    "\n",
    "[Lasagne](http://lasagne.readthedocs.org/en/latest/) is another, more full-featured, package, but we won't have time to go into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pickle lets us save python objects to a file and read them back in\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# here are our neural network imports\n",
    "#from sknn import mlp\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import theano\n",
    "\n",
    "import urllib.request\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# scikit-learn does have a restricted boltzman machine class for doing unsupervised\n",
    "# feature learning\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where Theano will run our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(theano.config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had a GPU, we could use it by setting `theano.config.device='gpu'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron with a Single Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), a standard dataset of handwritten digits.  Note that this is a much bigger, higher resolution dataset than the handwritten digits dataset that we've seein in previous lectures.  In this first example, we'll use scikit-neuralnetwork and then Lasagne.  The following code is a modified version based off of the Lasagne MNIST example [here](https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll download the MNIST dataset as a pickle file, save it to a local file, and then read in its contents.  If we've already downloaded the file, we'll just read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_URL = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
    "DATA_FILENAME = 'mnist.pkl.gz'\n",
    "\n",
    "if not os.path.exists(DATA_FILENAME):\n",
    "    print(\"Downloading MNIST dataset...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, DATA_FILENAME)\n",
    "\n",
    "with gzip.open(DATA_FILENAME, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle object has a training set, a validation set, and a test set.  Let's split those out and make a dictionary of things to pass to Theano/Lasagne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = data[0]\n",
    "X_valid, y_valid = data[1]\n",
    "X_test, y_test = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images of handwritten digits are 28 by 28 pixels (28*28=784):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01171875,  0.0703125 ,  0.0703125 ,\n",
       "        0.0703125 ,  0.4921875 ,  0.53125   ,  0.68359375,  0.1015625 ,\n",
       "        0.6484375 ,  0.99609375,  0.96484375,  0.49609375,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.1171875 ,  0.140625  ,  0.3671875 ,  0.6015625 ,\n",
       "        0.6640625 ,  0.98828125,  0.98828125,  0.98828125,  0.98828125,\n",
       "        0.98828125,  0.87890625,  0.671875  ,  0.98828125,  0.9453125 ,\n",
       "        0.76171875,  0.25      ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.19140625,  0.9296875 ,\n",
       "        0.98828125,  0.98828125,  0.98828125,  0.98828125,  0.98828125,\n",
       "        0.98828125,  0.98828125,  0.98828125,  0.98046875,  0.36328125,\n",
       "        0.3203125 ,  0.3203125 ,  0.21875   ,  0.15234375,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.0703125 ,  0.85546875,  0.98828125,  0.98828125,\n",
       "        0.98828125,  0.98828125,  0.98828125,  0.7734375 ,  0.7109375 ,\n",
       "        0.96484375,  0.94140625,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.3125    ,  0.609375  ,  0.41796875,  0.98828125,  0.98828125,\n",
       "        0.80078125,  0.04296875,  0.        ,  0.16796875,  0.6015625 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.0546875 ,\n",
       "        0.00390625,  0.6015625 ,  0.98828125,  0.3515625 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.54296875,\n",
       "        0.98828125,  0.7421875 ,  0.0078125 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04296875,  0.7421875 ,  0.98828125,\n",
       "        0.2734375 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.13671875,  0.94140625,  0.87890625,  0.625     ,\n",
       "        0.421875  ,  0.00390625,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.31640625,  0.9375    ,  0.98828125,  0.98828125,  0.46484375,\n",
       "        0.09765625,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.17578125,\n",
       "        0.7265625 ,  0.98828125,  0.98828125,  0.5859375 ,  0.10546875,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.0625    ,  0.36328125,\n",
       "        0.984375  ,  0.98828125,  0.73046875,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.97265625,  0.98828125,\n",
       "        0.97265625,  0.25      ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.1796875 ,  0.5078125 ,\n",
       "        0.71484375,  0.98828125,  0.98828125,  0.80859375,  0.0078125 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.15234375,\n",
       "        0.578125  ,  0.89453125,  0.98828125,  0.98828125,  0.98828125,\n",
       "        0.9765625 ,  0.7109375 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.09375   ,  0.4453125 ,  0.86328125,  0.98828125,  0.98828125,\n",
       "        0.98828125,  0.98828125,  0.78515625,  0.3046875 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.08984375,  0.2578125 ,  0.83203125,  0.98828125,\n",
       "        0.98828125,  0.98828125,  0.98828125,  0.7734375 ,  0.31640625,\n",
       "        0.0078125 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.0703125 ,  0.66796875,  0.85546875,\n",
       "        0.98828125,  0.98828125,  0.98828125,  0.98828125,  0.76171875,\n",
       "        0.3125    ,  0.03515625,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.21484375,  0.671875  ,\n",
       "        0.8828125 ,  0.98828125,  0.98828125,  0.98828125,  0.98828125,\n",
       "        0.953125  ,  0.51953125,  0.04296875,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.53125   ,  0.98828125,  0.98828125,  0.98828125,\n",
       "        0.828125  ,  0.52734375,  0.515625  ,  0.0625    ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous handwritten digits dataset that we worked with was only 8 by 8 pixels.  Let's define a function so that we can look at some of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_handwritten_digit(the_image, label):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(the_image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4cc240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_num = 1220\n",
    "plot_handwritten_digit(X_train[image_num].reshape((28, 28)), y_train[image_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define some constants that will be used in the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll feed in this many training examples at a time\n",
    "#BATCH_SIZE = 600\n",
    "\n",
    "# this is how many times we'll go through the set of batches, i.e. a full pass over\n",
    "# all of the training data\n",
    "#NUM_EPOCHS = 10\n",
    "\n",
    "# number of units in the hidden layer\n",
    "#NUM_HIDDEN_UNITS = 512\n",
    "\n",
    "# these parameters control the gradient descent process to learn the weights\n",
    "#LEARNING_RATE = 0.01\n",
    "#MOMENTUM = 0.9 \n",
    "\n",
    "\n",
    "# number of units in a single hidden layer\n",
    "NUM_HIDDEN_UNITS = 512\n",
    "\n",
    "# these parameters control the gradient descent process to learn the weights\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9 \n",
    "\n",
    "# we'll feed in this many training examples at a time (for stochastic gradient descent)\n",
    "BATCH_SIZE = 600\n",
    "\n",
    "# this is how many times we'll go through the set of batches, i.e. a full pass over\n",
    "# all of the training data\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is quite popular.  Interestingly, it does not actually do computations -it provides a relatively easy to use syntax for setting up and training neural networks that can be combined with a computational backend (theano, tensorflow).  This makes it very convenient since the keras code you write when using a theano backend is the same as the code you'd write if you were using tensorflow as a backend.  Swapping between theano and tensorflow on the backend requires a simple change to the keras configuration file (should be located in the ```.keras``` folder in your root directory, and called ```keras.json```; see https://keras.io/backend/).\n",
    "\n",
    "For a list of keras commands, and references on what each does, see: https://keras.io/layers/core/.\n",
    "\n",
    "Thes examples are based on the example found at: \n",
    "https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py\n",
    "Be careful with keras examples -you have to go to the actual Github\n",
    "respository to get examples that are consistent with the latest version\n",
    "of the package, otherwise everything breaks...\n",
    "\n",
    "First, we setup the model.  This model is again simple - one layer for inputs, one hidden layer, and then one layer for outputs.  We will use sigmoid activation for the hidden layer, and softmax activation for the output layer.  This setup lets us perform classification -by taking the largest value in the softmax layer across the ten possible outputs (0, 1, ..., 9), we can classify new observations.  We will also measure our network's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_shape=(784,), activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tell keras we want to create a sequential (feed-forward network) model, in which one\n",
    "# layer follows the next\n",
    "model = Sequential()\n",
    "\n",
    "# Create the input layer and the hidden layer of the network\n",
    "# 'Dense' indicates that we want all inputs to connect to every node in the hidden layer\n",
    "# 'input_shape' tells the hidden layer the dimension of the input to expect, which is determined\n",
    "#    by our data (the number of predictors in our data set = 784 pixels per image)\n",
    "# 'NUM_HIDDEN_UNITS' (which we defined above) tells keras how many nodes are the hidden layer connected\n",
    "#    to the input layer\n",
    "# 'activation' specifies how values from the input node should be processed by hidden nodes.\n",
    "model.add(Dense(NUM_HIDDEN_UNITS, input_shape=(784,), activation='sigmoid', init='uniform'))\n",
    "\n",
    "# Next, we'll create an output layer.\n",
    "# The value '10' tells keras we want this layer to have ten nodes\n",
    "# The 'activation' tells keras we want to use the softmax function\n",
    "# Note that we don't specify 'input_shape'.  The input to this layer is the output of the hidden\n",
    "# layer we created above. keras is smart enough to figure this out, which is why we only need\n",
    "# to specify how many nodes are in the output layer.\n",
    "model.add(Dense(10, activation='softmax', init='uniform'))\n",
    "\n",
    "# Next, we specify the properties of our optimizer.\n",
    "# We'll be using stochastic gradient descent with momentum, along with \n",
    "# the crossentropy cost function.\n",
    "# Note: The 'decay' argument was not discussed in lecture - it reduces the learning\n",
    "# rate as we get further into training (e.g., as we go from one epoch to the next)\n",
    "# The benefit of decay is that the optimizer will make bigger adjustments\n",
    "# early on, then do fine-tuning later in the training process.\n",
    "sgd = SGD(lr=LEARNING_RATE, decay=1e-6, momentum=MOMENTUM, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "# Summarize the model setup\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The np_utils module is part of keras, and has functioan designed to make it easier to work with neural networks.\n",
    "# Here, we're using it to convert the label response data into vectors.\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, let's fit the model.  We pass it the training data, the batch_size (for SGD), and the number of epochs.  Notice the ```.fit``` syntax, which is the same syntax used for all scikit-learn models we've used thusfar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 2s - loss: 2.1062     - \n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s - loss: 1.5146     \n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s - loss: 1.0126     \n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.7620     \n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.6341     \n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.5590     \n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s - loss: 0.5094     \n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 1s - loss: 0.4743     \n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 1s - loss: 0.4486     \n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 1s - loss: 0.4287     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f9e6f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, nb_epoch=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll predict on the test set using the neural network.  Since we had ten output nodes, keras will give us a 10-dimensional vector for each test observation.  Each entry in the vector can be interpreted as the probability that the test vector's label corresponds to the entry (e.g., first entry is the probability that the test observation is a `0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.59895867e-04,   1.18811486e-05,   8.88102368e-05, ...,\n",
       "          9.92178679e-01,   5.46572410e-05,   5.80947334e-03],\n",
       "       [  2.92448252e-02,   1.58728613e-03,   7.18269765e-01, ...,\n",
       "          4.67639120e-06,   1.83281917e-02,   1.12579255e-05],\n",
       "       [  1.00773352e-04,   9.53497231e-01,   1.24950185e-02, ...,\n",
       "          8.23997520e-03,   4.70800139e-03,   1.82167382e-03],\n",
       "       ..., \n",
       "       [  1.85203480e-05,   1.08833941e-04,   1.36234841e-04, ...,\n",
       "          6.08499488e-03,   2.77231671e-02,   1.69013709e-01],\n",
       "       [  1.63515657e-02,   1.52351148e-02,   6.58736192e-03, ...,\n",
       "          4.94785141e-03,   2.95459598e-01,   6.85393857e-03],\n",
       "       [  3.51337646e-03,   2.18260254e-07,   3.75234382e-03, ...,\n",
       "          1.80005571e-07,   5.54580001e-05,   7.12992778e-06]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_keras = model.predict(X_test)\n",
    "Y_test_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8640/10000 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also call predict_classes on the model to get the predicted labels directly, rather than probability vectors\n",
    "test_preds = model.predict_classes(X_test)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we measure the accuracy of the neural network.  Recall that precision is the fraction of observations labeled as a class that actually are of that class, and recall is the fraction of observations from a class that were labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       980\n",
      "          1       0.93      0.97      0.95      1135\n",
      "          2       0.90      0.85      0.87      1032\n",
      "          3       0.85      0.90      0.87      1010\n",
      "          4       0.84      0.94      0.89       982\n",
      "          5       0.88      0.79      0.83       892\n",
      "          6       0.91      0.91      0.91       958\n",
      "          7       0.89      0.90      0.90      1028\n",
      "          8       0.87      0.83      0.85       974\n",
      "          9       0.90      0.84      0.87      1009\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10000\n",
      "\n",
      "0.8919\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))\n",
    "print(accuracy_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to visualize what the hidden nodes are picking up on, we can extract the weights for a single hidden node, then pass those weights into the function we created earlier to plot digits.  This works because there is one weight per pixel, so the number of weights for a node can be rehaped into an 'image'.  When a pixel has a large weight, it will be darker in the image, and when a pixel has a low weight, it will lighter in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can extract the weights from the hidden layer using the get_weights\n",
    "# function provided by keras.\n",
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tell us that keras is tracking four sets of 'weights'. The first set of weights, model.get_weights()[0] corresponds to the weights used when mapping the inputs to the first hidden layer. The second set of weights, model.get_weights()[1], actually corresponds to the bias terms to the first hidden layers. The second two entries, indexed by 2 and 3 are the weights and biases applid to the hidden layer when mapping to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 512)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first set of weights is stored in an array with one row per pixel (i.e., one row per input node in our network), and one column per hidden node.  Therefore, if we want to see what pattern the a hidden node is detecting, we pass the corresponding weight column to the digit plot function we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqVYfiKlWH4ipVh+IqVYfiKl/g/NjzXf499yYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f58a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Which hidden node?\n",
    "hid_node = 450\n",
    "\n",
    "# Plot it\n",
    "# we're recylcing the function from before, so the title will still say\n",
    "# 'Training', but ignore that.\n",
    "plot_handwritten_digit(model.get_weights()[0][:,hid_node-1].reshape((28, 28)), hid_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0][:,1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper Network with Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try a deeper neural network with more layers.  Specifically, one input layer, two fully connected hidden layers using sigmoid activation, and one output layer using softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_shape=(784,), activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tell keras we want to create a sequential (feed-forward network) model, in which one\n",
    "# layer follows the next\n",
    "deeper_model = Sequential()\n",
    "\n",
    "# Create the input layer and the hidden layer of the network\n",
    "# 'Dense' indicates that we want all inputs to connect to every node in the hidden layer\n",
    "# 'input_shape' tells the hidden layer the dimension of the input to expect, which is determined\n",
    "#    by our data (the number of predictors in our data set = 784 pixels per image)\n",
    "# 'NUM_HIDDEN_UNITS' (which we defined above) tells keras how many nodes are the hidden layer connected\n",
    "#    to the input layer\n",
    "# 'activation' specifies how values from the input node should be processed by hidden nodes.\n",
    "deeper_model.add(Dense(NUM_HIDDEN_UNITS, input_shape=(784,), activation='sigmoid', init='uniform'))\n",
    "\n",
    "# Next, implement dropout in the first layer, with 50% of the input nodes being \n",
    "# dropped for each iteration.\n",
    "deeper_model.add(Dropout(0.5))\n",
    "\n",
    "# Next, create a second hidden layer with sigmoid activation, and\n",
    "# implement drop out.  Keras will look at the most layer we just created\n",
    "# to figure out how many inputs to expect.\n",
    "deeper_model.add(Dense(NUM_HIDDEN_UNITS, activation='sigmoid', init='uniform'))\n",
    "deeper_model.add(Dropout(0.5))\n",
    "\n",
    "# Next, we'll create the output layer.\n",
    "deeper_model.add(Dense(10, activation='softmax', init='uniform'))\n",
    "\n",
    "# Next, we specify the properties of our optimizer.\n",
    "# We'll be using stochastic gradient descent with momentum, along with \n",
    "# the crossentropy cost function.\n",
    "# Note: We're using a larger learning rate than in the single-layer network, and\n",
    "# and no decay.  I arrived at these settings through tuning, but intuitively this is \n",
    "# a more complicated function to optimize (given the additional layer)\n",
    "# and since I don't want to run over a huge number of epochs, I'm asking keras\n",
    "# to learn faster.  This may not always work in practice.\n",
    "sgd = SGD(lr=4.*LEARNING_RATE, decay=0., momentum=MOMENTUM, nesterov=True)\n",
    "deeper_model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "# Summarize the model setup\n",
    "deeper_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/civisemployee/anaconda3/envs/civis/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 4s - loss: 2.3208     \n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s - loss: 2.1674     \n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s - loss: 1.5823     \n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s - loss: 1.1307     \n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 5s - loss: 0.9192     \n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 5s - loss: 0.7876     \n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 5s - loss: 0.6991     \n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s - loss: 0.6347     \n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 5s - loss: 0.5944     - ETA: 0s - loss: 0.\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s - loss: 0.5596     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e477da0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the response once again, and train the network.\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "deeper_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, nb_epoch=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9568/10000 [===========================>..] - ETA: 0s             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      1028\n",
      "          1       0.99      0.96      0.97      1212\n",
      "          2       0.97      0.94      0.95      1005\n",
      "          3       0.92      0.96      0.94      1021\n",
      "          4       0.91      0.93      0.92      1061\n",
      "          5       0.94      0.88      0.91       863\n",
      "          6       0.97      0.93      0.95      1001\n",
      "          7       0.94      0.97      0.95      1009\n",
      "          8       0.89      0.98      0.93       832\n",
      "          9       0.91      0.88      0.89       968\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10000\n",
      "\n",
      "0.942\n"
     ]
    }
   ],
   "source": [
    "Y_test_deeper = deeper_model.predict_classes(X_test)\n",
    "#test_preds = np_utils.categorical_probas_to_classes(Y_test_keras)\n",
    "print(classification_report(Y_test_deeper, test_preds))\n",
    "print(accuracy_score(Y_test_deeper, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "Tensorflow is an open-source package provided by Google specifically designed for deep learning. In terms of what we've done so far in this notebook, it's comparable to theano in that it's a computational backend that can be paired with keras.  However, it can also be used directly (as can theano actually) to specify, train, and evaluate neural networks.  \n",
    "\n",
    "The basic idea behind tensorflow is to describe a network as a  'map' in which nodes correspond to computations (e.g., apply softmax function or sigmoid function), and the edges between nodes correspond to the flow of *tensors* (or multi-dimensional arrays) as they get processed via successive computations. Essentially, the tensors \"flow\" through the map, getting modified along the way.  \n",
    "\n",
    "Like theano, one key function of tensorflow is its ability to automatically calculate the derivatives required by gradient descent.  It figures out how all the parameters feed into the loss function, and calculates derivatives accordingly.\n",
    "\n",
    "In addition, tensorflow has many advanced features that we won't discuss.  For instance, it is designed to work well with GPU's, which have been found to be very good at performing the computations required by neural networks.  It can also be used for distributed processing, or even on smart phones.\n",
    "\n",
    "Instructions for installing tensorflow can be found here: https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html.  If you want the simplest possible install, I'd stick with the 'CPU Only' approach, which avoids having to setup additional packages required for GPU processing.\n",
    "\n",
    "Also, there now exists a tensorflow wrapper in R, which let's you use tensorflow without leaving R. I have not tried it, but if you do, let me know what you think.\n",
    "https://rstudio.github.io/tensorflow/\n",
    "\n",
    "Note that the R wrapper warns against installing tensorflow using anaconda, which is unfortunate.  I used the conda installation for use in Python, which worked fine.\n",
    "\n",
    "We'll now do the digit classification problem in tensorflow.  This example is heavily based on Google's own example: https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/examples/tutorials/mnist/mnist_softmax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Pull down the data in a tensforflow-friendly format\n",
    "mnist_tf = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data again consists of 28x28 pixel images, for 784 total pixes per image.  We therefore create a tensor flow *placeholder* to reprsent the input layer in our network.  We won't actually provide data yet -we're just telling tensorflow to expect data of a certain shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```float32``` tells tensorflow the type of data that will be stored in ```x```.  The ```[None,784]``` tells tensorflow to expect data with some (unspecified) number of rows, and 784 columns.\n",
    "\n",
    "Next, we need to add objects to our tensorflow map that correspond to the weights and biases of our neural network.  Specifically, we create tensorflow ```variables```, which can be updated as tensforflow performs gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weights and biases used to map inputs to hidden layer\n",
    "W = tf.Variable(tf.zeros([784,500]))\n",
    "b = tf.Variable(tf.zeros([500]))\n",
    "\n",
    "# Calculation of hidden layer using sigmoid activation\n",
    "h = tf.sigmoid(tf.matmul(x,W)+b)\n",
    "\n",
    "# Weights and biases used to map hidden layer to output layer\n",
    "hW = tf.Variable(tf.zeros([500,10]))\n",
    "hb = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Calculation to map hidden layer to output layer\n",
    "# Note: We'll apply softmax implicitly in the cost function\n",
    "y = tf.matmul(h,hW)+hb\n",
    "\n",
    "# Placeholder for the training response data\n",
    "y_ = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify our objective function, and how we'd like to update our parameters -in our case, via gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.9).minimize(cross_entropy)\n",
    "print(\"done\")  # this calculation can take a little while\n",
    "#train_step = tf.train.MomentumOptimizer(learning_rate=0.5,momentum=0.9).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we initialize all of the variables in the tensorflow map, start a session (tensorflow operations need to take place within a session), then iterate using the gradient descent algorithm in order to adjust the weights and minimize cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist_tf.train.next_batch(600)\n",
    "    sess.run(train_step,feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if i%100==0:\n",
    "        print(\"status update: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3129\n"
     ]
    }
   ],
   "source": [
    "# Lastly, we calculate accuracy of our fitted neural network\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess.run(accuracy,feed_dict={x: mnist_tf.test.images, y_: mnist_tf.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely bad, but I did no tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the tensorflow session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsurpervised Feature Learning with a Restricted Boltzmann Machine (RBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll do unsupervised feature learning, or dimensionality reduction.  This can be done with an autoencoder or a restricted boltzmann machine (RBM).  Without getting into too many of the details, both an autoencoder and an RBM have an input and a single hidden layer of reduced dimensionality.  The hidden layer is trained so that it can take the input and reconstruct it as accurately as possible, but with a smaller set of hidden nodes than input nodes.  Luckily for us, scikit-learn has an RBM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X_train = np.asarray(digits.data, 'float32')\n",
    "y_train = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take our training set and center it so that the features are all between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - np.min(X_train, 0)) / (np.max(X_train, 0) + 0.0001)  # 0-1 scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a random 10k observations to train on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EXAMPLES = 10000\n",
    "X_train_rbm, X_test_rbm, y_train_rbm, y_test_rbm = train_test_split(X_train, y_train, test_size=0.5, random_state=0)\n",
    "\n",
    "X_train_rbm = X_train_rbm[0:N_EXAMPLES]\n",
    "y_train_rbm = y_train_rbm[0:N_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBM needs a learning rate and a number of iterations to train for.  The parameter `n_components` tells it how many hidden nodes to use.  It's the dimensionality of the reduced dimension space (like PCA or t-SNE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(learning_rate=0.05, n_iter=20, n_components=200, random_state=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the RBM like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -27.16, time = 0.05s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.23, time = 0.08s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -25.94, time = 0.04s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -26.19, time = 0.04s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -25.71, time = 0.05s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -24.81, time = 0.06s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -24.67, time = 0.06s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -24.64, time = 0.05s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -22.60, time = 0.05s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -21.81, time = 0.09s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -21.89, time = 0.04s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -21.87, time = 0.04s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -21.52, time = 0.05s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -22.05, time = 0.07s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -21.39, time = 0.05s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -21.83, time = 0.04s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -21.24, time = 0.04s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -20.96, time = 0.06s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -21.21, time = 0.05s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -21.12, time = 0.05s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.05, n_components=200, n_iter=20,\n",
       "       random_state=0, verbose=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.fit(X_train_rbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what kinds of features the hidden nodes are learning, we can plot each node as a 28 by 28 pixel image where the darkness is how large the weight is connecting the hidden node to the corresponding input node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEiCAYAAAC7lxTyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCT046dChIyuhBycdOnRkJf4fUmwf7dtVmmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x143e1c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(rbm.components_):\n",
    "    plt.subplot(10, 20, i + 1)\n",
    "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.suptitle('Components extracted by the RBM', fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look in more detail at some of the individual hidden nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rbm_component(comp_num):\n",
    "    plt.figure(figsize=(4.2, 4))\n",
    "\n",
    "    comp = rbm.components_[comp_num]\n",
    "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABSJJREFUeJzt3b9OlGkYxuFncAf/ECiMSyxIMBYQEjuPwIRSjoeT8ADs\nLW3sbSgorCgpjYbRkGxjNFMwAt8WGwuyhTObzLPeu9dVf8n9kvDLS8U7GoahgCwr//YBgMUJFwIJ\nFwIJFwIJFwIJFwIJFwIJFwIJFwL9tsjHGxsbw+bm5rLOcsPV1VXLTlXV169f27aqqmazWdvWeDxu\n2+r8uVZWeu+c9fX1lp0vX77UdDod/ey7hcLd3NysFy9e/PNTLeDbt28tO1VVb9++bduqqjo7O2vb\nevDgQdvWZDJp27p7927bVlXVs2fPWnZevnw513f+VIZAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVA\nwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAC/1D9KqqYRiWcY6/\nOTk5admpqnr9+nXbVlXVwcFB29b+/n7b1qtXr9q2Li8v27aqqm7fvt2yMxr99BGDqnLjQiThQiDh\nQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDh\nQiDhQiDhQiDhQiDhQqCFniAZjUZtTzEcHR217FRVXV9ft21VVR0eHrZtPX36tG3rzZs3bVunp6dt\nW1VVs9msZWfeJ37cuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBI\nuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBoobeDvn//Xp8/f17WWW44Pz9v2anq\nexfmh4uLi7at6XTatnXr1q22ra7fwx8ePnzYsjMej+f6zo0LgYQLgYQLgYQLgYQLgYQLgYQLgYQL\ngYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgRZ6\ngmQ8Hrc9xXDv3r2Wnaq+5yV+mEwmbVvr6+v/ya1Hjx61bVVV3blzp2VnZWW+u9SNC4GEC4GEC4GE\nC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GE\nC4GEC4GEC4GEC4EWeoLk4uKiPnz4sKSj3LS3t9eyU/XX0yqdrq+v27aOj4/btu7fv9+29fz587at\nX5EbFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJ\nFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIt9ATJ6upqbW1tLessNzx58qRlp6rq/fv3bVtVVe/evWvb\nWl1dbdva3t5u29rZ2Wnbqqra2Nho2Zn3ORw3LgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQS\nLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgRa6O2gYRjq\n8vJyWWe5YXd3t2Wnqurjx49tW1VVR0dHbVuHh4dtW48fP27bWltba9uqqvr06VPLzjAMc33nxoVA\nwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVA\nwoVAwoVAwoVAwoVAwoVAwoVAo3mfPKiqGo1Gf1RV73sd8P+yPQzD7z/7aKFwgV+DP5UhkHAhkHAh\nkHAhkHAhkHAhkHAhkHAhkHAh0J9OYJCNYiC/vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1537d7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 60, 80, 90, 120\n",
    "plot_rbm_component(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a logistic regression trained using just the raw pixel values does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        89\n",
      "          1       0.94      0.94      0.94        90\n",
      "          2       0.98      0.98      0.98        92\n",
      "          3       0.97      0.94      0.95        93\n",
      "          4       0.97      0.97      0.97        76\n",
      "          5       0.94      0.95      0.94       108\n",
      "          6       0.96      0.98      0.97        89\n",
      "          7       0.95      1.00      0.97        78\n",
      "          8       0.93      0.86      0.89        92\n",
      "          9       0.90      0.92      0.91        92\n",
      "\n",
      "avg / total       0.95      0.95      0.95       899\n",
      "\n",
      "0.953281423804\n"
     ]
    }
   ],
   "source": [
    "N_LOGIT_TRAIN_EXAMPLES = 4000\n",
    "\n",
    "pixel_logit = LogisticRegression()\n",
    "pixel_logit.fit(X_train_rbm[0:N_LOGIT_TRAIN_EXAMPLES], y_train_rbm[0:N_LOGIT_TRAIN_EXAMPLES])\n",
    "\n",
    "# score it on the same test set we used above\n",
    "print(classification_report(y_test_rbm, pixel_logit.predict(X_test_rbm)))\n",
    "print(accuracy_score(y_test_rbm, pixel_logit.predict(X_test_rbm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how it does with the features learned by the RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96        89\n",
      "          1       0.72      0.70      0.71        90\n",
      "          2       0.77      0.82      0.79        92\n",
      "          3       0.78      0.73      0.76        93\n",
      "          4       0.95      0.93      0.94        76\n",
      "          5       0.92      0.67      0.77       108\n",
      "          6       0.92      0.93      0.93        89\n",
      "          7       0.72      0.91      0.80        78\n",
      "          8       0.79      0.63      0.70        92\n",
      "          9       0.61      0.77      0.68        92\n",
      "\n",
      "avg / total       0.81      0.80      0.80       899\n",
      "\n",
      "0.800889877642\n"
     ]
    }
   ],
   "source": [
    "rbm_logit = LogisticRegression()\n",
    "rbm_features_train = rbm.transform(X_train_rbm[0:N_LOGIT_TRAIN_EXAMPLES]) \n",
    "rbm_logit.fit(rbm_features_train, y_train_rbm[0:N_LOGIT_TRAIN_EXAMPLES])\n",
    "\n",
    "rbm_features_test = rbm.transform(X_test_rbm) \n",
    "print(classification_report(y_test_rbm, rbm_logit.predict(rbm_features_test)))\n",
    "print(accuracy_score(y_test_rbm, rbm_logit.predict(rbm_features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the hidden features learned by the RBM, and train a new RBM on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -117.73, time = 0.07s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -118.51, time = 0.10s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -118.87, time = 0.07s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -118.26, time = 0.07s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -118.17, time = 0.12s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -117.87, time = 0.06s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -118.00, time = 0.09s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -118.30, time = 0.08s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -117.53, time = 0.06s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -117.40, time = 0.06s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -117.15, time = 0.09s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -116.43, time = 0.06s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -115.77, time = 0.07s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -115.57, time = 0.06s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -115.64, time = 0.08s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -115.33, time = 0.09s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -115.09, time = 0.23s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -114.82, time = 0.13s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -114.35, time = 0.13s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -114.53, time = 0.11s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -114.05, time = 0.15s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -113.95, time = 0.09s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -114.12, time = 0.06s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -114.17, time = 0.06s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -114.16, time = 0.13s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -113.81, time = 0.12s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -114.23, time = 0.07s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -114.08, time = 0.08s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -113.87, time = 0.12s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -113.54, time = 0.08s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -113.99, time = 0.13s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -113.28, time = 0.15s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -113.80, time = 0.14s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -114.08, time = 0.16s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -114.06, time = 0.13s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -113.86, time = 0.06s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -113.75, time = 0.06s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -113.91, time = 0.06s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -113.49, time = 0.09s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -113.34, time = 0.07s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -113.46, time = 0.09s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.65, time = 0.08s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -114.08, time = 0.10s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -113.39, time = 0.06s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -113.58, time = 0.06s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -113.11, time = 0.09s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -113.38, time = 0.06s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -113.11, time = 0.09s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -112.92, time = 0.09s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -113.55, time = 0.06s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.05, n_components=150, n_iter=50,\n",
       "       random_state=0, verbose=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm_2 = BernoulliRBM(learning_rate=0.05, n_iter=50, n_components=150, random_state=0, verbose=True)\n",
    "rbm_2.fit(rbm_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94        89\n",
      "          1       0.55      0.43      0.48        90\n",
      "          2       0.60      0.85      0.70        92\n",
      "          3       0.79      0.63      0.70        93\n",
      "          4       0.92      0.95      0.94        76\n",
      "          5       0.62      0.19      0.30       108\n",
      "          6       0.98      0.92      0.95        89\n",
      "          7       0.40      0.91      0.56        78\n",
      "          8       0.66      0.23      0.34        92\n",
      "          9       0.54      0.71      0.61        92\n",
      "\n",
      "avg / total       0.69      0.66      0.64       899\n",
      "\n",
      "0.661846496107\n"
     ]
    }
   ],
   "source": [
    "rbm_logit_2 = LogisticRegression()\n",
    "rbm_features_train_2 = rbm_2.transform(rbm_features_train) \n",
    "rbm_logit_2.fit(rbm_features_train_2, y_train_rbm[0:N_LOGIT_TRAIN_EXAMPLES])\n",
    "\n",
    "rbm_features_test_2 = rbm_2.transform(rbm_features_test) \n",
    "print(classification_report(y_test_rbm, rbm_logit_2.predict(rbm_features_test_2)))\n",
    "print(accuracy_score(y_test_rbm, rbm_logit_2.predict(rbm_features_test_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
